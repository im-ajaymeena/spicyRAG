{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import subprocess\n",
    "import nltk\n",
    "import gc\n",
    "import random\n",
    "import torch\n",
    "import asyncio\n",
    "import hashlib\n",
    "\n",
    "from deepgram_transcribe import transcribe_file\n",
    "from span_marker import SpanMarkerModel\n",
    "import jsonschema\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "from deepgram import (\n",
    "    DeepgramClient,\n",
    "    DeepgramClientOptions,\n",
    "    PrerecordedOptions,\n",
    "    FileSource,\n",
    ")\n",
    "import logging\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "from llama_index.core import Document, SimpleDirectoryReader, VectorStoreIndex, get_response_synthesizer, PromptTemplate, StorageContext, load_index_from_storage\n",
    "from llama_index.core.schema import MetadataMode, TextNode, NodeRelationship, RelatedNodeInfo, ImageNode\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SimpleNodeParser\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from openai import OpenAI as OpenAI4DALLE\n",
    "openai_client4dalle = OpenAI4DALLE()\n",
    "\n",
    "from llama_index.core.extractors import (\n",
    "    TitleExtractor,\n",
    "    BaseExtractor,\n",
    ")\n",
    "from llama_index.core.vector_stores.types import ExactMatchFilter, MetadataFilters, MetadataFilter, FilterOperator\n",
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.core.query_engine import CitationQueryEngine\n",
    "from llama_index.multi_modal_llms.anthropic.base import AnthropicMultiModal\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "KNOWN_RECIPE_QA_PROMPT_TMPL_STR = \"\"\"\n",
    "A man is preparing {recipe_title} dish the audio transcript is below.\n",
    "_________________________________________________________\n",
    "{context_str}\n",
    "_________________________________________________________\n",
    "\n",
    "Given the context information only and not prior knowledge, 'Write a detailed Food Recipe' in stepwise manner, each step should consist of heading and deatiled single line instructions.\n",
    "The recipe should contain as much details as possible including the ingredients, ingredients quatity, style of cooking, utensils and instrument usage. \n",
    "For first step of recipe list out all the ingredients\n",
    "\n",
    "About the output format:\n",
    "The receipe output should be a json format consisting of sequential steps as a list and each step is a dictornary with keys heading and instructions\n",
    "For example/reference I am sharing expected output for the Recipe of Coconut panna cotta\n",
    "\n",
    "[\n",
    "    {{\n",
    "        \"heading\": \"Ingredients\",\n",
    "        \"instructions\": \"We will need: 2 cups coconut milk, 1/2 cup granulated sugar, 2 teaspoons powdered gelatin, 2 tablespoons cold water, 1 teaspoon vanilla extract, Coconut cream for topping (optional)\"\n",
    "    }},\n",
    "    {{\n",
    "        \"heading\": \"Preparing the Coconut Milk Mixture\",\n",
    "        \"instructions\": \"In a medium-sized saucepan, pour 2 cups of coconut milk. Place the saucepan over medium heat and warm the coconut milk, stirring occasionally. Be careful not to let it boil. Once the coconut milk is warm, add 1/2 cup of granulated sugar to it. Stir continuously until the sugar is completely dissolved. This usually takes about 2-3 minutes.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"heading\": \"Blooming the Gelatin\",\n",
    "        \"instructions\": \"In a small bowl, sprinkle 2 teaspoons of powdered gelatin over 2 tablespoons of cold water. Make sure the water is cold to properly activate the gelatin. Allow the gelatin to sit undisturbed for about 5 minutes. During this time, the gelatin will absorb the water and become soft, or 'bloom'.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"heading\": \"Incorporating Gelatin into Coconut Milk Mixture\",\n",
    "        \"instructions\": \"Once the gelatin has bloomed, it will have a spongy texture. Add the bloomed gelatin to the warm coconut milk mixture in the saucepan. Stir the mixture continuously until the gelatin is completely dissolved into the coconut milk. This usually takes 2-3 minutes of stirring over medium heat.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"heading\": \"Adding Vanilla Extract\",\n",
    "        \"instructions\": \"After the gelatin is fully dissolved, add 1 teaspoon of vanilla extract to the coconut milk mixture in the saucepan. Stir well to evenly distribute the vanilla extract throughout the mixture. This adds a delightful aroma and flavor to the panna cotta.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"heading\": \"Pouring into Glasses and Chilling\",\n",
    "        \"instructions\": \"Once the coconut milk mixture is ready, remove the saucepan from the heat. Carefully pour the mixture into individual serving glasses or ramekins. Fill each glass leaving about 1/4 inch of space at the top. Place the glasses on a tray and transfer them to the refrigerator. Allow the panna cotta to chill and set in the refrigerator for at least 4 hours. For best results, refrigerate overnight.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"heading\": \"Adding Coconut Cream Topping (Optional)\",\n",
    "        \"instructions\": \"If desired, before serving, spoon a layer of coconut cream over the chilled panna cotta in each glass. This adds an extra layer of coconut flavor and enhances the presentation of the dessert.\"\n",
    "    }},\n",
    "    {{\n",
    "        \"heading\": \"Serving\",\n",
    "        \"instructions\": \"Once set, remove the Coconut Panna Cotta from the refrigerator. Serve chilled, optionally garnished with shredded coconut or fresh fruit, and enjoy!\"\n",
    "    }}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "MODIFY_RECIPE_QA_PROMPT_TMPL_STR = \"\"\"\n",
    "A man is preparing {recipe_title} dish the audio transcript is below.\n",
    "_________________________________________________________\n",
    "{context_str}\n",
    "_________________________________________________________\n",
    "\n",
    "Using the above context information and recipe modification request belowt: \n",
    "_______________________________________________\n",
    "{modification_request}\n",
    "______________________________________________\n",
    "'Write a detailed Food Recipe' in stepwise manner, each step should consist of heading and deatiled single line instructions.\n",
    "The recipe should contain as much details as possible including the ingredients, ingredients quatity, style of cooking, utensils and instrument usage. \n",
    "For first step of recipe list out all the ingredients\n",
    "\n",
    "At the same time modify whereever required to incorporate the modification_request: {modification_request}\n",
    "Please be careful that the modifications should be such that the sequential steps of food-recipe are coherent, \n",
    "logical and does not completely remove the essence of orignal recipe\n",
    "\n",
    "According to user request we can change ingridents, spiciness, add additional content for improving nutritional-content etc, \n",
    "but we want to keep the core values and style of original author \n",
    "You can use knowledge other than the context for performing modifications\n",
    "\n",
    "Also give title to this new recipe after according to modifications done and output it in 'recipe_title' field of output json\n",
    "\n",
    "\n",
    "About the output format:\n",
    "The receipe output should be a json format consisting of sequential steps as a list and each step is a dictornary with keys heading and instructions\n",
    "For example/reference I am sharing expected\n",
    "\n",
    "\n",
    "{{\n",
    "    \"recipe_title\": \"Recipe of Coconut panna cotta\",\n",
    "    \"steps\": [\n",
    "        {{\n",
    "            \"heading\": \"Ingredients\",\n",
    "            \"instructions\": \"We will need: 2 cups coconut milk, 1/2 cup granulated sugar, 2 teaspoons powdered gelatin, 2 tablespoons cold water, 1 teaspoon vanilla extract, Coconut cream for topping (optional)\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Preparing the Coconut Milk Mixture\",\n",
    "            \"instructions\": \"In a medium-sized saucepan, pour 2 cups of coconut milk. Place the saucepan over medium heat and warm the coconut milk, stirring occasionally. Be careful not to let it boil. Once the coconut milk is warm, add 1/2 cup of granulated sugar to it. Stir continuously until the sugar is completely dissolved. This usually takes about 2-3 minutes.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Blooming the Gelatin\",\n",
    "            \"instructions\": \"In a small bowl, sprinkle 2 teaspoons of powdered gelatin over 2 tablespoons of cold water. Make sure the water is cold to properly activate the gelatin. Allow the gelatin to sit undisturbed for about 5 minutes. During this time, the gelatin will absorb the water and become soft, or 'bloom'.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Incorporating Gelatin into Coconut Milk Mixture\",\n",
    "            \"instructions\": \"Once the gelatin has bloomed, it will have a spongy texture. Add the bloomed gelatin to the warm coconut milk mixture in the saucepan. Stir the mixture continuously until the gelatin is completely dissolved into the coconut milk. This usually takes 2-3 minutes of stirring over medium heat.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Adding Vanilla Extract\",\n",
    "            \"instructions\": \"After the gelatin is fully dissolved, add 1 teaspoon of vanilla extract to the coconut milk mixture in the saucepan. Stir well to evenly distribute the vanilla extract throughout the mixture. This adds a delightful aroma and flavor to the panna cotta.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Pouring into Glasses and Chilling\",\n",
    "            \"instructions\": \"Once the coconut milk mixture is ready, remove the saucepan from the heat. Carefully pour the mixture into individual serving glasses or ramekins. Fill each glass leaving about 1/4 inch of space at the top. Place the glasses on a tray and transfer them to the refrigerator. Allow the panna cotta to chill and set in the refrigerator for at least 4 hours. For best results, refrigerate overnight.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Adding Coconut Cream Topping (Optional)\",\n",
    "            \"instructions\": \"If desired, before serving, spoon a layer of coconut cream over the chilled panna cotta in each glass. This adds an extra layer of coconut flavor and enhances the presentation of the dessert.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Serving\",\n",
    "            \"instructions\": \"Once set, remove the Coconut Panna Cotta from the refrigerator. Serve chilled, optionally garnished with shredded coconut or fresh fruit, and enjoy!\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "\n",
    "UNKNOWN_RECIPE_QA_PROMPT_TMPL_STR = \"\"\"\n",
    "From multiple food recipes prepared by a specifc man we have listed some his techniques/style to mix ingredients and process food etc\n",
    "From those randomly collected-recipe-steps, you have to compose a detailed recipe by assembling/modifying the provided \n",
    "collected-recipe-steps into a coherent, step-by-step cooking guide. \n",
    "\n",
    "Your task is to ensure that the resultant recipe flows naturally, adheres to a logical progression, and maintains the \n",
    "structure of a typical food recipe, while ensuring the preservation of the author's unique style and choice of utilizing the ingredients.\n",
    "\n",
    "Begin by organizing the steps in a sequential structure, ensuring that each follows the previous one chronologically. \n",
    "\n",
    "Incorporate ingredients incrementally as they are required in the cooking process. \n",
    "Describe when each ingredient should be added, ensuring that the introduction of each aligns with its \n",
    "appropriate step similar to how done in collected-recipe-steps. \n",
    "\n",
    "Use imperative verbs to denote actions, quantities, in style similar to authors.\n",
    "\n",
    "Conclude the recipe with instructions on serving the finished dish, including any garnishes or \n",
    "accompaniments in style similar to authors..\n",
    "\n",
    "For all the instruction keep the cooking style similar to that seen in collected-recipe-steps\n",
    "\n",
    "the context from collected-recipe-steps is below\n",
    "_____________________________________\n",
    "{context_str}\n",
    "_____________________________________\n",
    "\n",
    "About the output format:\n",
    "The receipe output should be a json format consisting of sequential steps as a list and each step is a dictornary with keys heading and instructions\n",
    "For example/reference I am sharing expected\n",
    "\n",
    "\n",
    "{{\n",
    "    \"recipe_title\": \"Recipe of Coconut panna cotta\",\n",
    "    \"steps\": [\n",
    "        {{\n",
    "            \"heading\": \"Ingredients\",\n",
    "            \"instructions\": \"We will need: 2 cups coconut milk, 1/2 cup granulated sugar, 2 teaspoons powdered gelatin, 2 tablespoons cold water, 1 teaspoon vanilla extract, Coconut cream for topping (optional)\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Preparing the Coconut Milk Mixture\",\n",
    "            \"instructions\": \"In a medium-sized saucepan, pour 2 cups of coconut milk. Place the saucepan over medium heat and warm the coconut milk, stirring occasionally. Be careful not to let it boil. Once the coconut milk is warm, add 1/2 cup of granulated sugar to it. Stir continuously until the sugar is completely dissolved. This usually takes about 2-3 minutes.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Blooming the Gelatin\",\n",
    "            \"instructions\": \"In a small bowl, sprinkle 2 teaspoons of powdered gelatin over 2 tablespoons of cold water. Make sure the water is cold to properly activate the gelatin. Allow the gelatin to sit undisturbed for about 5 minutes. During this time, the gelatin will absorb the water and become soft, or 'bloom'.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Incorporating Gelatin into Coconut Milk Mixture\",\n",
    "            \"instructions\": \"Once the gelatin has bloomed, it will have a spongy texture. Add the bloomed gelatin to the warm coconut milk mixture in the saucepan. Stir the mixture continuously until the gelatin is completely dissolved into the coconut milk. This usually takes 2-3 minutes of stirring over medium heat.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Adding Vanilla Extract\",\n",
    "            \"instructions\": \"After the gelatin is fully dissolved, add 1 teaspoon of vanilla extract to the coconut milk mixture in the saucepan. Stir well to evenly distribute the vanilla extract throughout the mixture. This adds a delightful aroma and flavor to the panna cotta.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Pouring into Glasses and Chilling\",\n",
    "            \"instructions\": \"Once the coconut milk mixture is ready, remove the saucepan from the heat. Carefully pour the mixture into individual serving glasses or ramekins. Fill each glass leaving about 1/4 inch of space at the top. Place the glasses on a tray and transfer them to the refrigerator. Allow the panna cotta to chill and set in the refrigerator for at least 4 hours. For best results, refrigerate overnight.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Adding Coconut Cream Topping (Optional)\",\n",
    "            \"instructions\": \"If desired, before serving, spoon a layer of coconut cream over the chilled panna cotta in each glass. This adds an extra layer of coconut flavor and enhances the presentation of the dessert.\"\n",
    "        }},\n",
    "        {{\n",
    "            \"heading\": \"Serving\",\n",
    "            \"instructions\": \"Once set, remove the Coconut Panna Cotta from the refrigerator. Serve chilled, optionally garnished with shredded coconut or fresh fruit, and enjoy!\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "\n",
    "KNOWN_RECIPE_QA_PROMPT_TMPL = PromptTemplate(KNOWN_RECIPE_QA_PROMPT_TMPL_STR)\n",
    "UNKNOWN_RECIPE_QA_PROMPT_TMPL = PromptTemplate(UNKNOWN_RECIPE_QA_PROMPT_TMPL_STR)\n",
    "MODIFY_RECIPE_QA_PROMPT_TMPL = PromptTemplate(MODIFY_RECIPE_QA_PROMPT_TMPL_STR)\n",
    "\n",
    "\n",
    "KNOWN_RECIPE_RESPONSE_SCHEMA = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"heading\": {\"type\": \"string\"},\n",
    "            \"instructions\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"heading\", \"instructions\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "UNKNOWN_RECIPE_RESPONSE_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"recipe_title\": {\"type\": \"string\"},\n",
    "        \"steps\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"heading\": {\"type\": \"string\"},\n",
    "                    \"instructions\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"heading\", \"instructions\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"recipe_title\", \"steps\"],\n",
    "    \"additionalProperties\": False\n",
    "}\n",
    "\n",
    "\n",
    "MMLM_REFINE_PROMPT = \"\"\" \n",
    "I have a food-recipe-step and corresponding images, \n",
    "From the images I want you to add new information to the food-recipe-step \n",
    "given food-recipe-step and images, output should be single line\n",
    "\n",
    "find additional details or clarifications from images only, do not use any prior knowledge\n",
    "then combine the extracted information from images with existing information \n",
    "(only use information from images which you are confident of) ensuring that the instructions remain clear, coherent.  \n",
    "The final output should have tone like single line instructions which allow other users to cook recipe in accurately\n",
    "Do not add any other statement like \"Based on the image\" etc only output the response directly\n",
    "\n",
    "\n",
    "the recipe-step is below\n",
    "_____________________\n",
    "{step}\n",
    "_____________________\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "IMG_GENERATION_PROMPT_TMPL = \"\"\"\n",
    "We want to help user by explaining the Food Recipe steps in visual manner, \n",
    "I'll ask to generate image for one of the steps but do incorporate knowledge from steps before than candidate step\n",
    "Below are the json formatted steps for Food Recipe named {recipe_title}, \n",
    "____________\n",
    "{steps}\n",
    "___________\n",
    "\n",
    "generate image which depicts the scenario for the instruction in step {step_index} which is \n",
    "__________________\n",
    "{step_instruction}\n",
    "_________________\n",
    "( please incorporate the previous steps, recipe title and ingridents aswell for better coherency between steps)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "VIDEO_DIR = 'yt_data'\n",
    "AUDIO_DIR = 'audio_data'\n",
    "TRANSCRIPT_PICKLE_PATH = \"audio_file_transcripts.pkl\"\n",
    "CHUNK_ENTITY_EXTRACT = True\n",
    "RECIPE_YOUTUBE_PLAYLIST = \"https://youtube.com/playlist?list=PL_PgxS3FkP7ATPveBQ1yah7LDqysyzDCG&si=GUM8RS-uuvVfV8GH\"\n",
    "VIDEO_FRAME_RATE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_videos():\n",
    "    subprocess.call(['yt-dlp', '-i', RECIPE_YOUTUBE_PLAYLIST])\n",
    "\n",
    "def transcribe_file(AUDIO_FILE):\n",
    "    try:\n",
    "        # STEP 1 Create a Deepgram client using the API key in the environment variables\n",
    "        config: DeepgramClientOptions = DeepgramClientOptions(\n",
    "            verbose=logging.SPAM,\n",
    "        )\n",
    "        deepgram: DeepgramClient = DeepgramClient(config=config)\n",
    "        # OR use defaults\n",
    "        # deepgram: DeepgramClient = DeepgramClient()\n",
    "\n",
    "        # STEP 2 Call the transcribe_file method on the prerecorded class\n",
    "        with open(AUDIO_FILE, \"rb\") as file:\n",
    "            buffer_data = file.read()\n",
    "\n",
    "        payload: FileSource = {\n",
    "            \"buffer\": buffer_data,\n",
    "        }\n",
    "\n",
    "        options: PrerecordedOptions = PrerecordedOptions(\n",
    "            model=\"whisper-large\",\n",
    "            smart_format=True,\n",
    "            punctuate=True,\n",
    "        )\n",
    "\n",
    "        response = deepgram.listen.prerecorded.v(\"1\").transcribe_file(\n",
    "            payload, options, timeout=httpx.Timeout(300.0, connect=10.0)\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "\n",
    "\n",
    "def video2audio():\n",
    "    for video_file in os.listdir(VIDEO_DIR):\n",
    "        video_path = os.path.join(VIDEO_DIR, video_file)\n",
    "        audio_filename = f'{os.path.join(AUDIO_DIR, os.path.basename(video_path))}.wav'\n",
    "        cmd = ['ffmpeg', '-loglevel', 'warning', '-n', '-i', f'{video_path}', f'{audio_filename}']\n",
    "        subprocess.call(cmd)\n",
    "\n",
    "def audio2text_pickle():\n",
    "    audio_file_transcripts = {}\n",
    "    for audio_file in os.listdir(AUDIO_DIR):\n",
    "        audio_file_path = os.path.join(AUDIO_DIR, audio_file)\n",
    "        response = transcribe_file(audio_file_path)\n",
    "        audio_file_transcripts[audio_file] = response['results']['channels'][0]['alternatives'][0]['paragraphs']['paragraphs']\n",
    "    \n",
    "    with open(TRANSCRIPT_PICKLE_PATH, \"wb\") as file:\n",
    "        pickle.dump(audio_file_transcripts,file)\n",
    "\n",
    "    return audio_file_transcripts\n",
    "\n",
    "\n",
    "def get_transcript_dict():\n",
    "    if os.path.exists(TRANSCRIPT_PICKLE_PATH):\n",
    "        with open(TRANSCRIPT_PICKLE_PATH,'rb') as file:\n",
    "            audio_file_transcripts = pickle.load(file)\n",
    "        return audio_file_transcripts\n",
    "    \n",
    "    else:\n",
    "        raise \"transcrip file not found\"\n",
    "\n",
    "\n",
    "def get_file_transcript_list():\n",
    "    file_transcript_list = []\n",
    "\n",
    "    audio_file_transcripts = get_transcript_dict()\n",
    "    \n",
    "    for audio_file, transcript in audio_file_transcripts.items():\n",
    "        filename = os.path.basename(audio_file)\n",
    "        file_transcript_list.append({\"filename\": filename, \"transcript\": transcript})\n",
    "    \n",
    "    return file_transcript_list\n",
    "\n",
    "def get_file_hash(filename):\n",
    "    hasher = hashlib.sha1()\n",
    "    hasher.update(filename.encode('utf-8'))  \n",
    "    return hasher.hexdigest()\n",
    "\n",
    "hash2file_map = {get_file_hash(filename): filename for filename in os.listdir(AUDIO_DIR)}\n",
    "\n",
    "if not os.path.exists(VIDEO_DIR):\n",
    "    get_youtube_videos()\n",
    "\n",
    "if not os.path.exists(AUDIO_DIR):\n",
    "    video2audio()\n",
    "\n",
    "if not os.path.exists(TRANSCRIPT_PICKLE_PATH):\n",
    "    audio2text_pickle()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load text data in TextNodes format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_paragraph_info(paragraph):\n",
    "    text = \"\"\n",
    "    for sentence in paragraph['sentences']:\n",
    "        text += f\"{ sentence.text}\"\n",
    "    return text, paragraph['start'], paragraph['end']\n",
    "\n",
    "def concatenated_transcript(transcript):\n",
    "    text = \"\"\n",
    "    for paragraph in transcript:\n",
    "        paragraph_text, _, _ = get_paragraph_info(paragraph)\n",
    "        text += f\"{paragraph_text}\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_recipe_title(text):\n",
    "    messages = [\n",
    "    ChatMessage(\n",
    "            role=\"system\", content=\"You are a food receipe title extractor which only output title as a nouns, if cannot find return None\"\n",
    "        ),\n",
    "        ChatMessage(role=\"user\", content=f\"{text}\"),\n",
    "    ]\n",
    "    resp = OpenAI().chat(messages)\n",
    "    return resp.message.content\n",
    "\n",
    "class RecipeSearchQueryExtractor(BaseExtractor):\n",
    "    metadata_mode = MetadataMode.EMBED\n",
    "    \n",
    "    async def aextract(self, nodes):\n",
    "        metadata_list = []\n",
    "        for node in nodes:\n",
    "            recipe_title = node.metadata['recipe_title']\n",
    "            if recipe_title == 'None':\n",
    "                recipe_title = node.metadata[\"document_title\"]\n",
    "            \n",
    "            questions = (\n",
    "                f\"How to make {recipe_title}?\\n\"  +\n",
    "                f\"Share the recipe for {recipe_title}\\n\"  +\n",
    "                f\"I want to make {recipe_title}, how should I do?\\n\"  +\n",
    "                f\"Write steps for preparing {recipe_title}\"\n",
    "            )\n",
    "\n",
    "            metadata_list.append({\"recipe_queries\": questions})\n",
    "\n",
    "\n",
    "        return metadata_list\n",
    "\n",
    "async def get_file_nodes(filename, timestamped_transcript, filehash):\n",
    "    doc = Document(\n",
    "        text=concatenated_transcript(timestamped_transcript),\n",
    "        metadata = {\n",
    "            'filehash': filehash,\n",
    "            'recipe_title': extract_recipe_title(filename)\n",
    "            },\n",
    "        excluded_llm_metadata_keys = [\"recipe_queries\"]\n",
    "    )\n",
    "    text_splitter = TokenTextSplitter(\n",
    "        separator=\" \", chunk_size=512,\n",
    "    )\n",
    "    node_template = \"Context: {context_str}. Fetch all the major food entities or recipe title found in the context. Title: \"\n",
    "    combine_template = \"{context_str}. Using ONLY above titles and food entities, create a food recipe title which is being prepared, the recipe title should not be more than 5 words? Title: \"\n",
    "\n",
    "    title_extractor = TitleExtractor(\n",
    "        nodes=5,\n",
    "        node_template = node_template,\n",
    "        combine_template=combine_template \n",
    "        )\n",
    "    \n",
    "\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[text_splitter, title_extractor, RecipeSearchQueryExtractor()]\n",
    "    )\n",
    "    \n",
    "    file_nodes = await pipeline.arun(documents=[doc])\n",
    "\n",
    "    return file_nodes\n",
    "\n",
    "# Function to generate hash for each node's metadata, useful for persistent node ID generation\n",
    "def generate_node_hash(node_data):\n",
    "    json_str = json.dumps(node_data, sort_keys=True)\n",
    "    hash_value = hashlib.sha256(json_str.encode()).hexdigest()\n",
    "    return hash_value\n",
    "\n",
    "class NodeEntityExtractor():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.ENTITY_SCORE_THRESHOLD = 0.8\n",
    "        self.entity_model = SpanMarkerModel.from_pretrained(\"tomaarsen/span-marker-mbert-base-multinerd\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.entity_model.cuda()\n",
    "    \n",
    "    def __call__(self, text):\n",
    "\n",
    "        food_entities = []\n",
    "        texts = nltk.sent_tokenize(text)\n",
    "        for outputs in self.entity_model.predict(texts):\n",
    "            if not isinstance(outputs, list): outputs = [outputs]\n",
    "            for entity in outputs:\n",
    "                if entity['label'] == 'FOOD' and entity['score'] > self.ENTITY_SCORE_THRESHOLD:\n",
    "                    food_entities.append(entity['span']) \n",
    "\n",
    "        return {\n",
    "            'food_in_context': food_entities, \n",
    "            }\n",
    "    \n",
    "    def unload_from_cuda(self):\n",
    "        if torch.cuda.is_available():\n",
    "            del self.entity_model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "def get_pnodes(timestamped_transcript, filehash):\n",
    "\n",
    "    nodes = []\n",
    "    node1 = None\n",
    "    for paragraph in timestamped_transcript:\n",
    "        node_text, start_time, end_time = get_paragraph_info(paragraph)\n",
    "        node_metadata = {\n",
    "            'start_time': start_time, \n",
    "            'end_time': end_time, \n",
    "            'filehash': filehash,\n",
    "            }\n",
    "        node_hash = generate_node_hash({**node_metadata, 'text': node_text})\n",
    "\n",
    "        node2 = TextNode(id_=node_hash, text=node_text, metadata=node_metadata)\n",
    "        if node1:\n",
    "            node1.relationships[NodeRelationship.CHILD] = RelatedNodeInfo(\n",
    "                node_id=node2.node_id\n",
    "            )\n",
    "        node1 = node2\n",
    "        nodes.append(node2)\n",
    "    \n",
    "    if CHUNK_ENTITY_EXTRACT:    \n",
    "        for node in nodes:\n",
    "            node.metadata = {**node.metadata, **entity_extractor(node.text)}\n",
    "    return nodes\n",
    "    \n",
    "\n",
    "\n",
    "pnodes = []\n",
    "file_nodes = []\n",
    "\n",
    "file_transcript_list = get_file_transcript_list()\n",
    "entity_extractor = NodeEntityExtractor()\n",
    "\n",
    "for file_transcript in file_transcript_list:\n",
    "    filename = file_transcript['filename']\n",
    "    timestamped_transcript = file_transcript['transcript']\n",
    "    \n",
    "    print(f'processing file {filename}')\n",
    "\n",
    "    filehash = get_file_hash(filename)\n",
    "\n",
    "    file_nodes.extend(await get_file_nodes(file_transcript['filename'], timestamped_transcript, filehash))\n",
    "    pnodes.extend(get_pnodes(timestamped_transcript, filehash))\n",
    "\n",
    "entity_extractor.unload_from_cuda()\n",
    "print(f\"len of transcripts nodes {len(pnodes)}\")\n",
    "print(f\"total no. of file nodes: containing description of each video file -> {len(file_nodes)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract frames from video corresponding to each text-chunk (TextNode). Save them in ./extracted_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def run_frame_extract_command(node, semaphore):\n",
    "    async with semaphore:\n",
    "        start_time = node.metadata['start_time']\n",
    "        end_time = node.metadata['end_time'] \n",
    "        filehash = node.metadata['filehash']\n",
    "        time_duration = int(end_time - start_time)\n",
    "\n",
    "        video_path = os.path.join(VIDEO_DIR, os.path.join(hash2file_map[filehash][:-4]))\n",
    "\n",
    "        save_dir = f'./extracted_frames/{filehash}/{node.node_id}/'\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        command = [\n",
    "            'ffmpeg', '-n', '-hide_banner', '-loglevel', 'error', '-ss', f'{start_time}', \n",
    "            '-i', f'{video_path}', '-vf', \"select='eq(pict_type\\,I)'\", '-t', f'{time_duration}', \n",
    "            '-vsync', '0', '-frame_pts', 'true', f'{save_dir}%05d.jpg'\n",
    "            ]\n",
    "\n",
    "        process = await asyncio.create_subprocess_exec(*command)\n",
    "        await process.wait()\n",
    "\n",
    "semaphore = asyncio.Semaphore(10)\n",
    "frame_extract_tasks = []\n",
    "for node in pnodes:\n",
    "    frame_extract_tasks.append(run_frame_extract_command(node, semaphore))\n",
    "\n",
    "await asyncio.gather(*frame_extract_tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_nodes = []\n",
    "framepath_absolute_timestamp_maping = {}\n",
    "\n",
    "for node in pnodes:\n",
    "    get_file_paths = lambda dir: [os.path.join(dir, i) for i in os.listdir(dir)]\n",
    "    relevant_frames_dir = os.path.join('extracted_frames', node.metadata['filehash'], node.node_id)\n",
    "    relevant_frames_paths = get_file_paths(relevant_frames_dir)\n",
    "    for frame_path in relevant_frames_paths:\n",
    "        image_nodes.append(ImageNode(image_path=frame_path, metadata={**node.metadata, 'node_id': node.node_id}))\n",
    "        framepath_absolute_timestamp_maping[frame_path] = float(node.metadata['start_time']) + float(os.path.basename(frame_path).split('.')[0])/VIDEO_FRAME_RATE\n",
    "\n",
    "print(image_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "# Create PGVectorStore instance\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=\"vector_db\",\n",
    "    host=\"0.0.0.0\",\n",
    "    password=\"password\",\n",
    "    port=5432,\n",
    "    user=\"postgres\",\n",
    "    table_name=\"image_collection\",\n",
    "    embed_dim=512\n",
    ")\n",
    "\n",
    "image_storage_context = StorageContext.from_defaults(image_store=vector_store)\n",
    "image_index = MultiModalVectorStoreIndex(\n",
    "    image_nodes,\n",
    "    storage_context=image_storage_context,\n",
    "    show_progress=True\n",
    "    )\n",
    "\n",
    "file_index = VectorStoreIndex(file_nodes)\n",
    "pindex = VectorStoreIndex(pnodes)\n",
    "\n",
    "file_retriever = file_index.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([(node.metadata['document_title'], node.metadata['recipe_title']) for node in file_nodes])\n",
    "# print([ node.text for node in file_nodes[0:1]])\n",
    "# print([ node.text for node in file_nodes[1:2]])\n",
    "# print([ node.text for node in file_nodes[2:3]])\n",
    "# print([node.metadata['recipe_title'] for node in file_nodes])\n",
    "# print(file_nodes)\n",
    "# print(pnodes)\n",
    "# print([node.node_id for node in pnodes])\n",
    "# print(image_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_template(json_response, steps_images, recipe_query, source=None):\n",
    "    markdown_template = f\"<h2>User query: {recipe_query}</h2>\"\n",
    "    if source: markdown_template += f\"<h4>course {source}</h4>\"\n",
    "\n",
    "    for step in json_response:\n",
    "        heading = step[\"heading\"]\n",
    "        instructions = step[\"instructions\"]\n",
    "        \n",
    "        markdown_template += f\"<h3>{heading}</h3>\"\n",
    "\n",
    "        if heading in steps_images:\n",
    "            image_paths = steps_images[heading]\n",
    "            images_html = \"\"\n",
    "            for image_path in image_paths:\n",
    "                if source:\n",
    "                    frame_timestamp = framepath_absolute_timestamp_maping[image_path]\n",
    "                    timestamp_element = f\"<p>time: {round(frame_timestamp, 2)}sec</p>\"\n",
    "                else:\n",
    "                    timestamp_element = \"\"\n",
    "\n",
    "                images_html += f\"<div style='display: flex; flex-direction: column; align-items: flex-start;'><img src='{image_path}' style='width:240px;'>{timestamp_element}</div>\"\n",
    "            markdown_template += f\"<div style='display: flex;'>{images_html}</div>\\n\"\n",
    "        \n",
    "        for ind, sentence in enumerate(nltk.sent_tokenize(instructions)):\n",
    "            markdown_template += f\"<p>{ind+1}. {sentence}</p>\\n\"\n",
    "    \n",
    "    return markdown_template\n",
    "\n",
    "def get_generated_image_url(prompt):\n",
    "  response = openai_client4dalle.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=prompt,\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "  )\n",
    "\n",
    "  image_url = response.data[0].url\n",
    "  return image_url\n",
    "\n",
    "def refine_with_mmlm(response, images):\n",
    "    anthropic_mm_llm = AnthropicMultiModal(max_tokens=300)\n",
    "\n",
    "    for step in response:\n",
    "        if images[step['heading']]:\n",
    "            image_documents = SimpleDirectoryReader(\n",
    "                input_files=images[step['heading']]\n",
    "            ).load_data()\n",
    "            step['instructions'] = anthropic_mm_llm.complete(\n",
    "                prompt=MMLM_REFINE_PROMPT.format(step=step['instructions']),\n",
    "                image_documents=image_documents,\n",
    "                ).text\n",
    "    return response\n",
    "    \n",
    "\n",
    "def get_images4step(response):\n",
    "    response_json = json.loads(response.response)\n",
    "    referenced_nodes = [sn.node for sn in response.source_nodes]\n",
    "    referenced_node_index = VectorStoreIndex(referenced_nodes)\n",
    "    split_step = False\n",
    "\n",
    "    all_step_image_paths = {'Ingredients': []}\n",
    "    for step in response_json:\n",
    "\n",
    "        if step['heading'] == 'Ingredients':\n",
    "            continue\n",
    "\n",
    "        instructions = step['instructions']\n",
    "        if split_step:\n",
    "            sentences = nltk.sent_tokenize(instructions)\n",
    "        else:\n",
    "            sentences = [instructions]\n",
    "        \n",
    "        step_citation_score_nodes = []\n",
    "        for sentence in sentences:\n",
    "            step_citation_score_nodes.extend(referenced_node_index.as_query_engine().retrieve(sentence)[:3])\n",
    "        \n",
    "        step_citation_node_ids = set()\n",
    "        for item in step_citation_score_nodes:\n",
    "            step_citation_node_ids.add(item.node.node_id)\n",
    "        \n",
    "\n",
    "        image_node_filters = MetadataFilters(\n",
    "            filters=[\n",
    "                MetadataFilter(key=\"node_id\", value=step_citation_node_ids, operator=FilterOperator.IN),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        image_retriever = image_index.as_retriever(\n",
    "            similarity_top_k=20,\n",
    "            filters=image_node_filters\n",
    "        )\n",
    "\n",
    "        retrived_image_score_nodes = []\n",
    "        for sentence in nltk.sent_tokenize(instructions):\n",
    "            retieved_nodes = image_retriever.retrieve(sentence)\n",
    "            retrived_image_score_nodes.extend(retieved_nodes)\n",
    "        \n",
    "        retrived_image_nodes = []\n",
    "        for retrived_image_score_node in retrived_image_score_nodes:\n",
    "            if retrived_image_score_node.node not in retrived_image_nodes:\n",
    "                retrived_image_nodes.append(retrived_image_score_node.node)\n",
    "        \n",
    "        retrived_image_nodes = sorted(retrived_image_nodes, key=lambda x: (x.metadata['start_time'], os.path.basename(x.image_path)))\n",
    "        retrived_image_nodes_img_paths = [r.image_path for r in retrived_image_nodes]\n",
    "        all_step_image_paths[step['heading']] = retrived_image_nodes_img_paths\n",
    "\n",
    "    return all_step_image_paths\n",
    "\n",
    "def generate_recipe(recipe_query: str) -> None:\n",
    "\n",
    "    def generate_modified_recipe(recipe_query: str, modification_request: str) -> None:\n",
    "        \"\"\"If user request to do some sort of modification over some recipe, this recive:1) recipe which user mentioned 2) the modification request for that recipe\"\"\"\n",
    "\n",
    "        if modification_request is None:\n",
    "            generate_known_dish_recipe(recipe_query)\n",
    "\n",
    "        file_nodes = file_retriever.retrieve(recipe_query)\n",
    "        retrieved_file_hash = file_nodes[0].metadata[\"filehash\"]\n",
    "        recipe_title = file_nodes[0].metadata['recipe_title']\n",
    "\n",
    "        filters = MetadataFilters(filters=[ExactMatchFilter(key=\"filehash\", value=retrieved_file_hash)])\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=pindex,\n",
    "            similarity_top_k=20,\n",
    "            filters=filters\n",
    "        )\n",
    "        \n",
    "        query_engine = RetrieverQueryEngine.from_args(retriever=retriever, text_qa_template=MODIFY_RECIPE_QA_PROMPT_TMPL.partial_format(recipe_title=recipe_title, modification_request=modification_request))\n",
    "        \n",
    "        max_tries, attempt = 10, 0\n",
    "        while attempt < max_tries:\n",
    "            response = query_engine.query('A step of food recipe')\n",
    "            try:\n",
    "                jsonschema.validate(instance=json.loads(response.response), schema=UNKNOWN_RECIPE_RESPONSE_SCHEMA)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                print(f\"Response does not follow the specified format:{e}\")\n",
    "\n",
    "        recipe_title = json.loads(response.response)['recipe_title']\n",
    "        steps = json.loads(response.response)['steps']\n",
    "        step_images = {}\n",
    "        for i, step in enumerate(json.loads(response.response)['steps']):\n",
    "            if step['heading'] == 'Ingredients':\n",
    "                continue\n",
    "            prompt = IMG_GENERATION_PROMPT_TMPL.format(recipe_title = recipe_title, steps=steps, step_index=i+1, step_instruction=step['instructions'])\n",
    "            step_images[step['heading']] = [get_generated_image_url(prompt)]\n",
    "\n",
    "        markdown = generate_markdown_template(steps, step_images, recipe_query)\n",
    "        display(Markdown(markdown))\n",
    "\n",
    "\n",
    "\n",
    "    def generate_custom_dish_recipe(recipe_query: str) -> None:\n",
    "        \"\"\"if query does not specify any Food or cuisine, or if user query want to generate new/novel recipe\"\"\"\n",
    "        \"\"\"displays custom food recipe in markdown format return nothing\"\"\"\n",
    "\n",
    "        node_ids = [n.node_id for n in pnodes]\n",
    "        picked_node_ids = random.sample(node_ids, 10)\n",
    "\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=pindex,\n",
    "            similarity_top_k=50,\n",
    "            node_ids=picked_node_ids\n",
    "        )\n",
    "        query_engine = RetrieverQueryEngine.from_args(retriever=retriever, text_qa_template=UNKNOWN_RECIPE_QA_PROMPT_TMPL)\n",
    "        max_tries, attempt = 10, 0\n",
    "    \n",
    "        while attempt < max_tries:\n",
    "            response = query_engine.query('A step of food recipe')\n",
    "            try:\n",
    "                jsonschema.validate(instance=json.loads(response.response), schema=UNKNOWN_RECIPE_RESPONSE_SCHEMA)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                print(f\"Response does not follow the specified format:{e}\")\n",
    "\n",
    "        recipe_title = json.loads(response.response)['recipe_title']\n",
    "        steps = json.loads(response.response)['steps']\n",
    "        step_images = {}\n",
    "        for i, step in enumerate(json.loads(response.response)['steps']):\n",
    "            if step['heading'] == 'Ingredients':\n",
    "                continue\n",
    "            prompt = IMG_GENERATION_PROMPT_TMPL.format(recipe_title = recipe_title, steps=steps, step_index=i+1, step_instruction=step['instructions'])\n",
    "            step_images[step['heading']] = [get_generated_image_url(prompt)]\n",
    "\n",
    "        markdown = generate_markdown_template(steps, step_images, recipe_query)\n",
    "        display(Markdown(markdown))\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def generate_known_dish_recipe(recipe_query: str) -> None:\n",
    "        \"\"\"In case any Food/Ingrident/cuisine is specified in query\"\"\"\n",
    "        \"\"\"displays food recipe and instructions for food or dish requested by user clearly\"\"\"\n",
    "        file_nodes = file_retriever.retrieve(recipe_query)\n",
    "\n",
    "        if file_nodes[0].score < 0.80:\n",
    "            display(Markdown(\"## Jaques can only help with french food.. Please submit another query\"))\n",
    "            return\n",
    "        \n",
    "        retrieved_file_hash = file_nodes[0].metadata[\"filehash\"]\n",
    "        # print(hash2file_map[retrieved_file_hash])\n",
    "        recipe_title = file_nodes[0].metadata['recipe_title']\n",
    "\n",
    "        # relavant_pnodes = [pnode for pnode in pnodes if pnode.metadata['filehash'] == retrieved_file_hash]\n",
    "        filters = MetadataFilters(filters=[ExactMatchFilter(key=\"filehash\", value=retrieved_file_hash)])\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=pindex,\n",
    "            similarity_top_k=20,\n",
    "            filters=filters\n",
    "        )\n",
    "        \n",
    "        query_engine = RetrieverQueryEngine.from_args(retriever=retriever, text_qa_template=KNOWN_RECIPE_QA_PROMPT_TMPL.partial_format(recipe_title=recipe_title))\n",
    "\n",
    "        while True:\n",
    "            response = query_engine.query('text containing instructions for food preparation')\n",
    "            try:\n",
    "                jsonschema.validate(instance=json.loads(response.response), schema=KNOWN_RECIPE_RESPONSE_SCHEMA)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Response does not follow the specified format:{e}\")\n",
    "\n",
    "        steps_images = get_images4step(response)\n",
    "    \n",
    "        refined_response = refine_with_mmlm(json.loads(response.response), steps_images)\n",
    "        markdown = generate_markdown_template(refined_response, steps_images, recipe_query, hash2file_map[retrieved_file_hash][:-4])\n",
    "\n",
    "        display(Markdown(markdown))\n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "    Custom_FoodRecipe_tool = FunctionTool.from_defaults(fn=generate_custom_dish_recipe)\n",
    "    Known_FoodRecipe_tool = FunctionTool.from_defaults(fn=generate_known_dish_recipe)\n",
    "    Modify_FoodRecipe_tool = FunctionTool.from_defaults(fn=generate_modified_recipe)\n",
    "\n",
    "\n",
    "    llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "    agent = OpenAIAgent.from_tools([Known_FoodRecipe_tool, Modify_FoodRecipe_tool, Custom_FoodRecipe_tool], llm=llm, verbose=True)\n",
    "\n",
    "    response = agent.chat(\n",
    "        recipe_query, tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_recipe(\"Could you share recipe for Roasted Chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Any, List\n",
    "# from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "# from llama_index.core.bridge.pydantic import PrivateAttr\n",
    "# from llama_index.core.embeddings import BadseEmbedding\n",
    "\n",
    "\n",
    "# class InstructorEmbeddings(BaseEmbedding):\n",
    "#     _model: INSTRUCTOR = PrivateAttr()\n",
    "#     _instruction: str = PrivateAttr()\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         instructor_model_name: str = \"hkunlp/instructor-base\",\n",
    "#         instruction: str = \"Represent a food receipe step for semantic search:\",\n",
    "#         **kwargs: Any,\n",
    "#     ) -> None:\n",
    "#         self._model = INSTRUCTOR(instructor_model_name, device='cuda')\n",
    "#         self._instruction = instruction\n",
    "#         super().__init__(**kwargs)\n",
    "\n",
    "#     @classmethod\n",
    "#     def class_name(cls) -> str:\n",
    "#         return \"instructor\"\n",
    "\n",
    "#     async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "#         return self._get_query_embedding(query)\n",
    "\n",
    "#     async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "#         return self._get_text_embedding(text)\n",
    "\n",
    "#     def _get_query_embedding(self, query: str) -> List[float]:\n",
    "#         embeddings = self._model.encode([[self._instruction, query]])\n",
    "#         return embeddings[0]\n",
    "\n",
    "#     def _get_text_embedding(self, text: str) -> List[float]:\n",
    "#         embeddings = self._model.encode([[self._instruction, text]])\n",
    "#         return embeddings[0]\n",
    "\n",
    "#     def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "#         embeddings = self._model.encode(\n",
    "#             [[self._instruction, text] for text in texts]\n",
    "#         )\n",
    "#         print(embeddings)\n",
    "#         return embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mightybot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
